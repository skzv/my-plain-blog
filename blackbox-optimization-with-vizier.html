<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1" /> <meta property="og:image" content="https://blog.skz.dev/assets/img/blackbox-optimization-with-vizier/black-box-optimization.png"> <meta name="twitter:image" content="https://blog.skz.dev/assets/img/blackbox-optimization-with-vizier/black-box-optimization.png"> <meta name="author" content="Sasha Kuznetsov"> <title>Blackbox Optimization and Hyperparameter Tuning With Google's Vizier · Sasha Kuznetsov's Blog</title> <meta property="og:title" content="Blackbox Optimization and Hyperparameter Tuning With Google's Vizier · Sasha Kuznetsov's Blog"> <meta name="twitter:title" content="Blackbox Optimization and Hyperparameter Tuning With Google's Vizier · Sasha Kuznetsov's Blog"> <meta name="description" content=" Automatically and intelligently optimize any kind of system"> <meta property="og:description" content=" Automatically and intelligently optimize any kind of system"> <meta name="twitter:description" content=" Automatically and intelligently optimize any kind of system"> <link rel="icon" href="https://blog.skz.dev/assets/img/favicon.png"> <link rel="apple-touch-icon" href="https://blog.skz.dev/assets/img/favicon.png"> <link rel="stylesheet" href="https://blog.skz.dev/assets/css/core.css"> <link rel="canonical" href="https://blog.skz.dev/blackbox-optimization-with-vizier"> <link rel="alternate" type="application/atom+xml" title="Sasha Kuznetsov's Blog" href="https://blog.skz.dev/feed.xml" /> <script src="/assets/js/load-mathjax.js" async></script> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:creator" content="@skzv"> </head> <body> <aside class="logo"> <a href="https://blog.skz.dev/" aria-label="My avatar"> <img src="https://avatars.githubusercontent.com/u/11140296?v=4" alt="Me!" class="logo-avatar"> </a> <span class="logo-prompt code">Back to Index</span> </aside> <div id="content"> <article> <div class="center"> <h1 class="title">Blackbox Optimization and Hyperparameter Tuning With Google's Vizier</h1> <time class="code">February 23, 2023</time> </div> <div class="divider"></div> <p class="description"> Automatically and intelligently optimize any kind of system </p> <style> img { max-height: 350px; } </style> <p>When you build an machine learning model - or some other kind of algorithmic system - you will have to make choices about the architecture of your system. For example, for a machine learning application, you may need to decide how many neurons to have in a neural network layer, or the rate of gradient descent. Or if you are building a <a href="https://en.wikipedia.org/wiki/Particle_filter">particle filter</a> to track the state of a robot, you may need to choose the shape of a likelihood function. You may be looking for a buffer size and thread count that minimize your use of computing resources. How can you find the optimal architecture for your system?</p> <p>You could try to find it manually. You can try different values for the number of neurons. You could try different rates of gradient descent. But this process is slow and tedious, and suceptible to pitfalls. Thankfully there exist services that can optimize your system for you, in an intelligent and efficient way.</p> <div class="divider"></div> <h2 id="introducing-vizier">Introducing Vizier</h2> <p><a href="https://github.com/google/vizier">Vizier</a> is an optimization service created at Google for blackbox and hyperparameter optimization. It can be used to optimize any kind of system as long as you can pass inputs to the system - that are suggested by Vizier - and get outputs from the system - metrics that Vizier is trying to optimize, such as by maximizing or minimizing them. The system itself is treated as a blackbox.</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/black-box-optimization.png" alt="Blackbox Optimization" /></p> <p class="caption"> Blackbox optimization doesn't requre any understanding of the system itself, as long as you can pass inputs and get outputs. Source: Per Instance Algorithm Configuration for Continuous Black Box Optimization - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/black-box-Optimization_fig1_322035981 [accessed 23 Feb, 2023] </p> <p>Unlike non-blackbox optimization systems such as <a href="https://blog.skz.dev/gradient-descent">gradient descent</a> which require an understanding of the relationship between the parameters of the system and the metric being minimized or maximized, a blackbox system like Vizier does not require any insight into the system itself. It can still search the parameter space efficiently for you, and find the values of the parameters that optimize your system. This also makes it more robust to complex, discontinuous and non-convex metric functions.</p> <div class="divider"></div> <h2 id="parameters-vs-hyperparameters">Parameters vs Hyperparameters</h2> <p>Aside: the distinction comes from machine learning applications, where “parameters” are considered the values inside the model used for inference and found through training on a dataset, while hyperparameters describe the architecture of the model or the training procedure. However, a blackbox optimization service like Vizier can be used to optimize any kind of system, but it won’t be an efficient way of training a machine learning model. But it is a good way to optimize the architecture of the model.</p> <div class="divider"></div> <h2 id="an-example">An Example</h2> <p>I am going to use an example that is not machine learning related, but still demonstrates the power and simplicity of a blackbox optimization algorithm such as Vizier. Say we have a noisy signal like the one below:</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/some-noisy-signal.png" alt="Some noisy signal" /></p> <p class="caption"> Some noisy signal. </p> <p>Let’s try to find an analytical function that fits this signal. We can’t decide if we want to fit a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian</a> or <a href="https://en.wikipedia.org/wiki/Laplace_distribution">Laplace</a> function to the signal, and both functions have their own parameters - such as mean and variance - that we are also trying to estimate.</p> <p>As long as we can give Vizier a metric we are trying to optimize, it will find an optimal function for us.</p> <div class="divider"></div> <h2 id="setting-up-the-problem">Setting Up The Problem</h2> <p>The first parameter we want to search is the model type: Gaussian or Laplace:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    'parameter_id': 'model',
    'categorical_value_spec' : {
        'values': [
            'gaussian',
            'laplace',
        ]
}
</code></pre></div></div> <p>But each model has its own set of parameters that defines its shape. Let’s call these “child parameters” of each model.</p> <p>For the Gaussian, these are the mean <code class="language-plaintext highlighter-rouge">mu</code> (\(\mu\)) and standard deviation <code class="language-plaintext highlighter-rouge">sigma</code> (\(\sigma\)).</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/normal-distribution.png" alt="Gaussian distribution with parameters mu and sigma." /></p> <p class="caption"> Gaussian distribution with parameters mu and sigma. Taken from: https://commons.wikimedia.org/wiki/File:Normal_Distribution_PDF.svg </p> <p>For the Laplace - the notation depends on the literature - but generally there is the location parameter or mean <code class="language-plaintext highlighter-rouge">mu</code> (\(\mu\)) and scale factor <code class="language-plaintext highlighter-rouge">b</code> (\(b\)).</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/laplace-distribution.png" alt="Laplace distribution with parameters mu and b." /></p> <p class="caption"> Laplace distribution with parameters mu and b. Taken from: https://commons.wikimedia.org/wiki/File:Laplace_pdf_mod.svg </p> <p>For disambiguity from the mean of the Gaussian, let’s refer to the location parameter of the Laplace distribution as <code class="language-plaintext highlighter-rouge">a</code> instead of <code class="language-plaintext highlighter-rouge">mu</code>.</p> <p>When trying to fit the Gaussian distribution, we don’t want Vizier to try to estimate the parameters of the Laplace distribution and vice versa. Luckily we can specify the parameters of each distribution as child, or conditional, parameters of the parent model parameter:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'conditional_parameter_specs': [
{
    "parameter_spec": {
        "parameter_id": "mu",
        "scale_type": 'UNIT_LINEAR_SCALE',
        "double_value_spec": {
        "min_value": 0,
        "max_value": 10.0,
        },
    },
    "parent_categorical_values": {
        "values": ['gaussian']
    }
},
{
    "parameter_spec": {
        "parameter_id": "sigma",
        "scale_type": 'UNIT_LINEAR_SCALE',
        "double_value_spec": {
        "min_value": 1e-1,
        "max_value": 5.0,
        },
    },
    "parent_categorical_values": {
        "values": ['gaussian']
    }
},
    {
    "parameter_spec": {
        "parameter_id": "a",
        "scale_type": 'UNIT_LINEAR_SCALE',
        "double_value_spec": {
        "min_value": 0,
        "max_value": 10.0,
        },
    },
    "parent_categorical_values": {
        "values": ['laplace']
    }
},
{
    "parameter_spec": {
        "parameter_id": "b",
        "scale_type": 'UNIT_LINEAR_SCALE',
        "double_value_spec": {
        "min_value": 1e-1,
        "max_value": 5.0,
        },
    },
    "parent_categorical_values": {
        "values": ['laplace']
    }
}]
</code></pre></div></div> <p>Lastly, we need to define the metric that Vizier will be to optimizing. I want to fit a function to the signal as closely as possible, and I will evaluate how well it fits the signal by calculating the sum of squares of residuals between the analytical function and the data. The smaller this number, the better the fit. All we need to tell Vizier is that there is this metric we are trying to minimize:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>metric_ssr = {
    'metric_id': 'sum_of_squared_residuals',
    'goal': 'MINIMIZE',
}
</code></pre></div></div> <p>We put all of this together and that defines our problem:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>study = {
    'display_name': 'vizier_experiment',
    'study_spec' :
    {
        'parameters': [param_model],
        'metrics': [metric_ssr]
    }
}
</code></pre></div></div> <p>Note that Vizier has no understanding of the parameters themselves. <code class="language-plaintext highlighter-rouge">Gaussian</code> and <code class="language-plaintext highlighter-rouge">Laplace</code> are simply types of a categorical parameter, and to Vizier have no meaning besides that. They are given meaning by my code that consumes them, but to Vizier, that code lives in a blackbox. I’m leaving out the code for brevity, but you can find it all at the link at the end of the article to see what I mean.</p> <div class="divider"></div> <h2 id="searching">Searching</h2> <p>For each trial, Vizier suggests a set of parameters for us to try. We evaluate how well these parameters work ourselves, calculate the metric (the sum of squared residuals) and return the result of the metric evaluation to Vizier. Vizier uses the result to generate the next set of parameters to try.</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/vizier-trials.png" alt="Vizier suggesting parameters for trials." /></p> <p class="caption"> Vizier suggesting parameters for trials. </p> <p>Notice that Vizier only suggests Gaussian parameters when the model is Gaussian, and vice versa for the Laplace model.</p> <p>How does Vizier search for optimal parameters? It can do a grid or random search, but the real magic is the combination of other algorithms it employs: Gaussian process bandits, linear combination search, or their variants.</p> <p>Via GCP we can check these cool charts of Vizier’s progress:</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/study-progress-table.png" alt="A study table showing the evolution of the metric being optimized and the parameters of each trial" /></p> <p class="caption"> A study table showing the evolution of the metric being optimized and the parameters of each trial. </p> <p><img src="/assets/img/blackbox-optimization-with-vizier/parallel-chart.png" alt="A parallel chart showing the sets of parameters attempted and the resulting metric value" /></p> <p class="caption"> A parallel chart showing the sets of parameters attempted and the resulting metric value. </p> <div class="divider"></div> <h2 id="optimized-fit">Optimized Fit</h2> <p>We can see that the Laplace distribution slightly wins out over the Gaussian:</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/optimal-parallel-chart.png" alt="Parallel chart zoomed in to show the top trials that minimize the sum of squared residuals. A better fit is found with a Laplace distribution than a Gaussian distribution." /></p> <p class="caption"> Parallel chart zoomed in to show the top trials that minimize the sum of squared residuals. A better fit is found with a Laplace distribution than a Gaussian distribution. </p> <p>We query Vizier for the optimal trial parameters and plot them:</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/noisy-signal-fit.png" alt="Optimized fit to noisy signal" /></p> <p class="caption"> Optimized parameters that fit the noisy signal. </p> <p>It’s almost a perfect fit! The parameters Vizier found are close to the parameters I used to generate the signal before adding noise: a Laplace distribution with \(a=5\) and \(b=2\).</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/original-laplace-signal.png" alt="Original laplace signal" /></p> <p class="caption"> Original Laplace signal. </p> <p>For comparison, a Gaussian would have a rounder peak and thinner tails.</p> <p><img src="/assets/img/blackbox-optimization-with-vizier/gaussian-signal.png" alt="Gaussian signal" /></p> <p class="caption"> A comparative Gaussian distribution. </p> <div class="divider"></div> <h2 id="how-can-i-reproduce-this">How Can I Reproduce This?</h2> <p>The colab I used to generate this article can be found <a href="https://github.com/skzv/vizier-blog-post/blob/main/vizier_blog_post.ipynb">here</a>. I used GCP’s Vertex AI Vizier API because it generates some cool charts like the ones I included in this post, but be aware it can be expensive ($1/trial). Vizier is also open-source and available <a href="https://github.com/google/vizier">here</a>.</p> </article> <div class="page-navigation code"> <a class="next" href="https://blog.skz.dev/telegram-stickerly-import-bot" title="NEXT: A Telegram Bot for Importing Sticker.ly Packs">&lt;&lt;</a> <span> &middot; </span> <a class="home" href="https://blog.skz.dev/" title="Back to Index">Index</a> <span> &middot; </span> <a class="prev" href="https://blog.skz.dev/monte-carlo-options-pricing" title="PREV: Monte Carlo Options Pricing">&gt;&gt;</a> </div> </div> <div class="footer"> <span class="block">&copy; 2026 Sasha Kuznetsov</span> <!-- <span class="block"><small>&lt;/&gt; Powered by <a href="https://jekyllrb.com/">Jekyll</a> and <a href="https://github.com/heiswayi/the-plain">The Plain theme</a>.</small></span> --> </div> <script async defer src="https://api.skz.dev/latest.js"></script> <noscript><img src="https://api.skz.dev/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript> <!-- <script async defer data-domain="blog.skz.dev" src="https://a-api.skz.dev/js/index.js"></script> --> </body> </html>
